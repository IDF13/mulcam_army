# -*- coding: utf-8 -*-
"""트위터 크롤링 함수 완료.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1whgEzgFhoosUZn3mf5LRTn3HUOR10a6w
    이진수 작성
"""

import pandas as pd
import numpy as np
import tweepy
from tweepy import OAuthHandler, API
import json, csv

class TwitterCrawling():

  "트위터 가수 크롤링 프로그램"

  def __init__(self, auth, api):
    global consumer_key
    global consumer_secret
    global access_token
    global access_token_secret
    self.auth = auth
    auth.set_access_token(access_token,access_token_secret)
    self.api = api


  def start(self,keyword,max_tweets,addr):
    # keyword = 트위 검색 단어
    # max_tweets = 트윗 최대 개수
    # addr = 파일 저장할 로컬 주소
    searched_tweets =[]
    last_id = -1
    while len(searched_tweets) < max_tweets:
      count = max_tweets - len(searched_tweets)
      try:
        new_tweets = self.api.search(q = keyword, count = count)
        if not new_tweets:
          break
        searched_tweets.extend(new_tweets)
        last_id = new_tweets[-1].id

      except tweepy.TweepError as e:
        break
      
    # 트윗에서 정보 추출
    name = []
    id = []
    mention = []
    date = []
    time = []

    for tweet in searched_tweets:
      created_time = str(tweet.created_at)
      time_split = created_time.split()

      name.append(tweet.user.name)
      id.append('@' + tweet.user.screen_name)
      mention.append(tweet.text)
      date.append(time_split[0])
      time.append(time_split[1])
    
    # 추출 정보로 딕셔너리 생성
    data_info = {}
    data_info['닉네임'] = name
    data_info['ID'] = id
    data_info['내용'] = mention
    data_info['날짜'] = date
    data_info['시간'] = time

    data_info_frame = pd.DataFrame(data_info)

    self.addr = addr # 저장할 로컬주소
    data_info_frame.to_excel(self.addr+keyword+'.xlsx')



# API 키
consumer_key = "xEgs1OPq00opCqFN1mZotiaqd"
consumer_secret = "9wVr1mBjxgXvpsFeXnEUTFW8eX8nJbadRJ0jpXIvFhYhK6MSDJ"
access_token = "1430024043634118662-qaQhHC44eN2KWO7eYa8nn4cecg6gdD"
access_token_secret = "XU812kRWuxU29mBFTg8HbMNnROuR1aJRTuH36oaxD08gi"

# 핸들러 생성 및 개인정보 인증요청
auth = OAuthHandler(consumer_key,consumer_secret)

# 액세스 요청
auth.set_access_token(access_token,access_token_secret)

# twitter API 생성
api = API(auth)

data = pd.read_csv('/content/drive/MyDrive/ML Deep/artist.csv')
name_artist = data.artistsName
name_artist

max_tweets = 1500 # 최대 검색 트윗 수 
addr = '/content/drive/MyDrive/ML Deep/'

for keyword in name_artist[:3]: # 아티스트 3명만 추출 후 엑셀 저장
  TC = TwitterCrawling(auth,api)
  TC.start(keyword,max_tweets,addr)