{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMeans(4_clusters)_seventeen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIzEXB_CkWsX",
        "outputId": "59da3685-069d-4b63-98ec-7baec433992c"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"k-means_code.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Ls1XFeatzdMivoFijtX0MuN9E7ADviAC\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "\"\"\"# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞\n",
        "ÎåìÍ∏ÄÏùÑ ÏñºÎßàÎÇò Î∂àÎü¨ÏôÄÏïº Ìï†Íπå\n",
        "\"\"\"\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞\n",
        "\n",
        "path = '/content/drive/MyDrive/[·ÑÄ·Ö©·Üº·Ñã·Ö≤] Mulcam_Army ·ÑÄ·Ö©·Üº·Ñã·Ö≤·Ñë·Ö©·ÜØ·ÑÉ·Ö•!/·Ñè·Ö≥·ÑÖ·Ö©·ÜØ·ÑÖ·Öµ·Üº ·Ñí·Ö°·Ü´ ·Ñå·Ö°·ÑÖ·Ö≠/k-pop_Radar·Ñã·Ö°·Ñê·Öµ·Ñâ·Ö≥·Ñê·Ö≥ ·Ñè·Ö≥·ÑÖ·Ö©·ÜØ·ÑÖ·Öµ·Üº ·Ñí·Ö°·ÜØ·ÑÉ·Ö°·Üº·Ñá·ÖÆ·Ü´/·Ñâ·ÖÆ·ÑÜ·Öµ·Ü´_·ÑÄ·Öß·ÜØ·ÑÄ·Ö™·ÑÜ·ÖÆ·ÜØ/'\n",
        "comment_file = 'prepro_stats_page_640·Ñâ·Ö¶·Ñá·Ö≥·Ü´·Ñê·Öµ·Ü´.csv' \n",
        "\n",
        "data = pd.read_csv(path+comment_file, encoding='utf-8', header=None)\n",
        "data.columns = ['comment','like','lang']\n",
        "print(len(data))\n",
        "data.head()\n",
        "\n",
        "data_ko = pd.DataFrame([kor[:1] for kor in data.values if kor[2] == '(ko)'], columns=['comment'])\n",
        "data_en = pd.DataFrame([en[:1] for en in data.values if en[2] == '(en)'], columns=['comment'])\n",
        "data_en.comment.values\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "for i in range(len(data_en.comment)):\n",
        "    data_en.comment[i] = str(data_en.comment[i])\n",
        "\n",
        "# Ïà´ÏûêÏ†úÍ±∞ / Î∞ëÏ§Ñ Ï†úÏô∏Ìïú ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞\n",
        "p = re.compile(\"[0-7]+\")\n",
        "z = re.compile(\"[8-9]+\")\n",
        "q = re.compile(\"\\W+\")\n",
        "r = re.compile('[^a-zA-Z]+')\n",
        "\n",
        "en = []\n",
        "for i in data_en.comment.values:\n",
        "    tokens = re.sub(p,\" \",i)\n",
        "    tokens = re.sub(z,\" \",tokens)\n",
        "    tokens = re.sub(q,\" \",tokens)\n",
        "    tokens = re.sub(r,\" \", tokens)\n",
        "    en.append(tokens)\n",
        "len(en)\n",
        "en[:2]\n",
        "\n",
        "# Î∂àÏö©Ïñ¥ Ï†úÍ±∞\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "# stop_words.update(('song','group','songs','youtube','views','time','https','girl','girls','people','yes','lol','video','part','member','members', 'look','way','guys','fans','fan'))\n",
        "\n",
        "res=[]\n",
        "for i in range(len(en)):\n",
        "    word_tokens = word_tokenize(en[i])\n",
        "\n",
        "    result = []\n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            result.append(w) \n",
        "    res.append(result)\n",
        "\n",
        "# print(word_tokens) \n",
        "print(res[:10])\n",
        "print(len(res))\n",
        "\n",
        "en_pos = []\n",
        "for i in range(len(res)):\n",
        "    tokens_pos = nltk.pos_tag(res[i])\n",
        "    en_pos.append(tokens_pos)\n",
        "\n",
        "en_pos[:5]\n",
        "\n",
        "# Î™ÖÏÇ¨Îäî NNÏùÑ Ìè¨Ìï®ÌïòÍ≥† ÏûàÏùåÏùÑ Ïïå Ïàò ÏûàÏùå\n",
        "en_NN=[]\n",
        "for i in range(len(en_pos)):\n",
        "    NN_words = []\n",
        "    for word, pos in en_pos[i]:\n",
        "        if 'NN' in pos:\n",
        "            NN_words.append(word)\n",
        "        elif 'NN' in pos:\n",
        "            NN_words.append(word)\n",
        "    en_NN.extend(NN_words)\n",
        "en_NN[:10]\n",
        "\n",
        "# df = pd.DataFrame(en_NN)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83238\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[['even', 'carat', 'let', 'admit', 'song', 'universal'], ['song', 'tells', 'song', 'need', 'billion', 'views', 'prove', 'legendary'], ['fan', 'say', 'song', 'another', 'level'], ['years', 'passed', 'song', 'still', 'legend', 'probably', 'legacy', 'passed', 'different', 'generation', 'generation', 'attacca', 'released', 'october', 'hope', 'able', 'reach', 'new', 'milestone', 'boys', 'lately', 'previous', 'comebacks', 'struggle', 'make', 'views', 'go', 'together', 'almost', 'years', 'ripe', 'already', 'still', 'lack', 'effort', 'whilst', 'seventeen', 'work', 'hard', 'satisfy', 'us', 'every', 'menu', 'aim', 'make', 'us', 'taste', 'unending', 'gose', 'segments', 'contents', 'hope', 'able', 'pay', 'back'], ['fan', 'really', 'like', 'songs', 'especially', 'one', 'deserves', 'attention', 'views'], ['funfact', 'everyone', 'agree', 'successful', 'comeback', 'seventeen'], ['proof', 'choreography', 'need', 'jumps', 'flips', 'beautifully', 'done', 'goes', 'well', 'music', 'probably', 'one', 'favorites', 'also', 'video', 'choreography', 'danced', 'x', 'speed', 'left', 'awe', 'well', 'synchronized'], ['forget', 'fandom', 'carat', 'comes', 'song'], ['proves', 'songs', 'need', 'badass', 'become', 'addictive'], ['seventeen', 'stan', 'like', 'guys', 'deserves', 'views', 'likes', 'masterpiece']]\n",
            "69835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['admit',\n",
              " 'song',\n",
              " 'universal',\n",
              " 'song',\n",
              " 'tells',\n",
              " 'views',\n",
              " 'fan',\n",
              " 'level',\n",
              " 'years',\n",
              " 'song']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsPhE4L_6UjY",
        "outputId": "45b62d09-578f-469a-d6e2-adb10f1153e8"
      },
      "source": [
        "## 3Îã®Ïñ¥ Ïù¥Ìïò ÏßßÏùÄ Îã®Ïñ¥ Ï†úÍ±∞\n",
        " # remove words less than three letters\n",
        "# print(res[1])\n",
        "# for word in res[1]:\n",
        "#     print(word)\n",
        "en_sent_less3=[]\n",
        "for i in range(len(res)):\n",
        "    tokens = [word for word in res[i] if len(word) >= 3]\n",
        "    en_sent_less3.append(tokens)\n",
        "en_sent_less3[:2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['even', 'carat', 'let', 'admit', 'song', 'universal'],\n",
              " ['song', 'tells', 'song', 'need', 'billion', 'views', 'prove', 'legendary']]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQjt3WNR6dFW",
        "outputId": "c2fde23b-bd94-4492-8620-1fa91d36449e"
      },
      "source": [
        "en_sent =[]\n",
        "for i in range(len(en_sent_less3)):\n",
        "    temp=\" \".join(en_sent_less3[i])\n",
        "    en_sent.append(temp)\n",
        "en_sent[:15]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['even carat let admit song universal',\n",
              " 'song tells song need billion views prove legendary',\n",
              " 'fan say song another level',\n",
              " 'years passed song still legend probably legacy passed different generation generation attacca released october hope able reach new milestone boys lately previous comebacks struggle make views together almost years ripe already still lack effort whilst seventeen work hard satisfy every menu aim make taste unending gose segments contents hope able pay back',\n",
              " 'fan really like songs especially one deserves attention views',\n",
              " 'funfact everyone agree successful comeback seventeen',\n",
              " 'proof choreography need jumps flips beautifully done goes well music probably one favorites also video choreography danced speed left awe well synchronized',\n",
              " 'forget fandom carat comes song',\n",
              " 'proves songs need badass become addictive',\n",
              " 'seventeen stan like guys deserves views likes masterpiece',\n",
              " 'today wan cry year anniversary thank seventeen give masterpiece song',\n",
              " 'remember watching way back release stanning svt really like hoshi without knowing deeper',\n",
              " 'seventeen song recommendations non fans home lean listen secret highlight change heaven cloud fast pace habit trauma good meplease give discography chance seventeen lot great songs',\n",
              " 'suppose cry title say really stop crying time find masterpiece comforting',\n",
              " 'nobody crys cuz crush love wan cry']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q30F-7Ii6mhg"
      },
      "source": [
        "data_en['en_sent']=en_sent"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "b5R_g5Zn6oMF",
        "outputId": "3787145e-196e-4bd8-8e23-f429cf79ead5"
      },
      "source": [
        "data_en.tail()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>en_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69830</th>\n",
              "      <td>im updated but i want to binge watch more svt ...</td>\n",
              "      <td>updated want binge watch svt videos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69831</th>\n",
              "      <td>anyways im currently binge watching their vliv...</td>\n",
              "      <td>anyways currently binge watching vlives help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69832</th>\n",
              "      <td>novesuity dino thank you tho ü•∞</td>\n",
              "      <td>novesuity dino thank tho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69833</th>\n",
              "      <td>lui quinto did you watch seventeen project big...</td>\n",
              "      <td>lui quinto watch seventeen project big debut a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69834</th>\n",
              "      <td>ÎßâÎÇ¥Ïò®ÌÉë seventeen im currently watching those</td>\n",
              "      <td>seventeen currently watching</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment                                            en_sent\n",
              "69830  im updated but i want to binge watch more svt ...                updated want binge watch svt videos\n",
              "69831  anyways im currently binge watching their vliv...       anyways currently binge watching vlives help\n",
              "69832                     novesuity dino thank you tho ü•∞                           novesuity dino thank tho\n",
              "69833  lui quinto did you watch seventeen project big...  lui quinto watch seventeen project big debut a...\n",
              "69834         ÎßâÎÇ¥Ïò®ÌÉë seventeen im currently watching those                       seventeen currently watching"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "KqeGJs2JktNt",
        "outputId": "065c0683-70b9-419d-b7ef-ddb3b7484279"
      },
      "source": [
        "# TF_IDF Î≤°ÌÑ∞Ìôî\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "docs = data_en\n",
        "# len(docs)\n",
        "docs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>en_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>even if you re not a carat let s all admit it ...</td>\n",
              "      <td>even carat let admit song universal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this song tells that some song s don t need bi...</td>\n",
              "      <td>song tells song need billion views prove legen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not a fan but i should say that this song is o...</td>\n",
              "      <td>fan say song another level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4 years have passed and this song is still a l...</td>\n",
              "      <td>years passed song still legend probably legacy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i m not a fan of them but i really like all of...</td>\n",
              "      <td>fan really like songs especially one deserves ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69830</th>\n",
              "      <td>im updated but i want to binge watch more svt ...</td>\n",
              "      <td>updated want binge watch svt videos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69831</th>\n",
              "      <td>anyways im currently binge watching their vliv...</td>\n",
              "      <td>anyways currently binge watching vlives help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69832</th>\n",
              "      <td>novesuity dino thank you tho ü•∞</td>\n",
              "      <td>novesuity dino thank tho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69833</th>\n",
              "      <td>lui quinto did you watch seventeen project big...</td>\n",
              "      <td>lui quinto watch seventeen project big debut a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69834</th>\n",
              "      <td>ÎßâÎÇ¥Ïò®ÌÉë seventeen im currently watching those</td>\n",
              "      <td>seventeen currently watching</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69835 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment                                            en_sent\n",
              "0      even if you re not a carat let s all admit it ...                even carat let admit song universal\n",
              "1      this song tells that some song s don t need bi...  song tells song need billion views prove legen...\n",
              "2      not a fan but i should say that this song is o...                         fan say song another level\n",
              "3      4 years have passed and this song is still a l...  years passed song still legend probably legacy...\n",
              "4      i m not a fan of them but i really like all of...  fan really like songs especially one deserves ...\n",
              "...                                                  ...                                                ...\n",
              "69830  im updated but i want to binge watch more svt ...                updated want binge watch svt videos\n",
              "69831  anyways im currently binge watching their vliv...       anyways currently binge watching vlives help\n",
              "69832                     novesuity dino thank you tho ü•∞                           novesuity dino thank tho\n",
              "69833  lui quinto did you watch seventeen project big...  lui quinto watch seventeen project big debut a...\n",
              "69834         ÎßâÎÇ¥Ïò®ÌÉë seventeen im currently watching those                       seventeen currently watching\n",
              "\n",
              "[69835 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9QzRrGv7OOr"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words = 'english', \n",
        "                        #min_df = 3,  # 3Ìöå ÎØ∏ÎßåÏúºÎ°ú Îì±Ïû•ÌïòÎäî ÌÜ†ÌÅ∞ÏùÄ Î¨¥Ïãú\n",
        "                        max_df = 0.95 # ÎßéÏù¥ Îì±Ïû•Ìïú Îã®Ïñ¥ 5%Ïùò ÌÜ†ÌÅ∞ÎèÑ Î¨¥Ïãú\n",
        "                        )\n",
        "docs_tf = tfidf.fit_transform(docs.comment.values)\n",
        "\n",
        "# (stop_words='english')\n",
        "# token_pattern='(?u)\\\\b\\\\w+\\\\b' or 't\\w+'\n",
        "# ngram_range : Îã®Ïñ¥Ïû• ÏÉùÏÑ±Ïóê ÌïÑÏöîÌïú ÌÜ†ÌÅ∞Ïùò ÌÅ¨Í∏∞       \n",
        "# listÏùº Í≤ΩÏö∞ : fit['']\n",
        "# https://wikidocs.net/33661 -> tf-idf Îß§Í∞úÎ≥ÄÏàò"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DXO-_yasx84",
        "outputId": "143c05ee-8996-448c-af85-6d25cff4f57c"
      },
      "source": [
        "docs.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69835, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtXKktlO-O3e",
        "outputId": "92cf4651-8876-4aea-de0e-d6d5b97d5437"
      },
      "source": [
        "docs_tf.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69835, 47677)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApeAyfIvb6mD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ecc8b2-4647-4f23-da34-eb156418af85"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "modelkmeans = KMeans(n_clusters =4, init='k-means++', n_init=300)\n",
        "modelkmeans.fit(docs_tf)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=4, n_init=300, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow7CgSynZpgR"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# inertia_arr = []\n",
        "# k_range = range(1,11)\n",
        "\n",
        "# for k in k_range :\n",
        "\n",
        "#   km = KMeans(n_clusters=4, random_state=200)\n",
        "#   km.fit(docs_tf)\n",
        "#   interia = km.inertia_\n",
        "\n",
        "#   print('k :', k, 'interia :', interia)\n",
        "\n",
        "#   inertia_arr.append(interia)\n",
        "\n",
        "# inertia_arr1 = np.array(inertia_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewc3d27cZuGf"
      },
      "source": [
        "# plt.plot(k_range, inertia_arr, marker='o')\n",
        "# plt.vlines(3, ymin=inertia_arr.min()*0.9999, ymax=inertia_arr.max()*1.0003, linestyles='--', colors = 'g')\n",
        "# plt.vlines(4, ymin=inertia_arr.min()*0.9999, ymax=inertia_arr.max()*1.0003, linestyles='--', colors = 'r')\n",
        "\n",
        "# plt.title('Elbow Method')\n",
        "# plt.xlabel('Number of clusters')\n",
        "# plt.ylabel('Inertia')\n",
        "# plt.show()\n",
        "# # k=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLe6vIgx8FEz"
      },
      "source": [
        "cluster_label = modelkmeans.labels_\n",
        "docs['cluster_label'] =  modelkmeans.labels_"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3gxfjW68aZT",
        "outputId": "202854bc-892e-4471-d3dd-58377f58f9e3"
      },
      "source": [
        "np.unique(modelkmeans.labels_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s51Op27OLss",
        "outputId": "8e3a1067-1780-4c9b-c500-bf03faac6ad6"
      },
      "source": [
        "# Íµ∞ÏßëÌôîÌïú Î†àÏù¥Î∏îÍ∞íÎì§ÏùÑ df Ïóê Ï∂îÍ∞ÄÌïòÍ∏∞\n",
        "\n",
        "docs['cluster_label'] = cluster_label\n",
        "print(docs.sort_values(by=['cluster_label']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 comment  ... cluster_label\n",
            "29700  r s carat the comments do nothing to the views...  ...             0\n",
            "39001  you all just shut up hoshi is a tiger that s j...  ...             0\n",
            "39002        you all just shut up hoshi is a tiger india  ...             0\n",
            "39003                                 indonesia fans too  ...             0\n",
            "39004     i think this person doesn t even know the boys  ...             0\n",
            "...                                                  ...  ...           ...\n",
            "7208                  denise welcome to the diamond life  ...             3\n",
            "51329                welli slipped into the diamond life  ...             3\n",
            "63019  warrance st thank you for supporting our boys ...  ...             3\n",
            "51258  welcome to diamond life thanks for loving seve...  ...             3\n",
            "46313  slip into the diamond life please we ll be wai...  ...             3\n",
            "\n",
            "[69835 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "TZVx6Ea98ibB",
        "outputId": "8bdc6f15-84ae-41a9-c6a0-283f29fedcf2"
      },
      "source": [
        "docs"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>en_sent</th>\n",
              "      <th>cluster_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>even if you re not a carat let s all admit it ...</td>\n",
              "      <td>even carat let admit song universal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this song tells that some song s don t need bi...</td>\n",
              "      <td>song tells song need billion views prove legen...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not a fan but i should say that this song is o...</td>\n",
              "      <td>fan say song another level</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4 years have passed and this song is still a l...</td>\n",
              "      <td>years passed song still legend probably legacy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i m not a fan of them but i really like all of...</td>\n",
              "      <td>fan really like songs especially one deserves ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69830</th>\n",
              "      <td>im updated but i want to binge watch more svt ...</td>\n",
              "      <td>updated want binge watch svt videos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69831</th>\n",
              "      <td>anyways im currently binge watching their vliv...</td>\n",
              "      <td>anyways currently binge watching vlives help</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69832</th>\n",
              "      <td>novesuity dino thank you tho ü•∞</td>\n",
              "      <td>novesuity dino thank tho</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69833</th>\n",
              "      <td>lui quinto did you watch seventeen project big...</td>\n",
              "      <td>lui quinto watch seventeen project big debut a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69834</th>\n",
              "      <td>ÎßâÎÇ¥Ïò®ÌÉë seventeen im currently watching those</td>\n",
              "      <td>seventeen currently watching</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69835 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  ... cluster_label\n",
              "0      even if you re not a carat let s all admit it ...  ...             2\n",
              "1      this song tells that some song s don t need bi...  ...             2\n",
              "2      not a fan but i should say that this song is o...  ...             2\n",
              "3      4 years have passed and this song is still a l...  ...             0\n",
              "4      i m not a fan of them but i really like all of...  ...             0\n",
              "...                                                  ...  ...           ...\n",
              "69830  im updated but i want to binge watch more svt ...  ...             0\n",
              "69831  anyways im currently binge watching their vliv...  ...             0\n",
              "69832                     novesuity dino thank you tho ü•∞  ...             1\n",
              "69833  lui quinto did you watch seventeen project big...  ...             0\n",
              "69834         ÎßâÎÇ¥Ïò®ÌÉë seventeen im currently watching those  ...             2\n",
              "\n",
              "[69835 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWtSRk3o9gA8"
      },
      "source": [
        "cluster_centers =  modelkmeans.cluster_centers_"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbMlrAY5OYSr",
        "outputId": "fc15f7a1-3f5d-413d-9e48-956e345a2559"
      },
      "source": [
        "print(cluster_centers.shape)\n",
        "print(cluster_centers)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 47677)\n",
            "[[2.35109073e-03 3.71999814e-05 9.11891947e-06 ... 0.00000000e+00\n",
            "  1.79484878e-05 1.26914975e-05]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.47362472e-04 0.00000000e+00 0.00000000e+00 ... 5.84160653e-05\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FtI5G3qyFA4I",
        "outputId": "78a6e310-482b-4d3b-910b-24215244c32a"
      },
      "source": [
        "docs"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>en_sent</th>\n",
              "      <th>cluster_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>even if you re not a carat let s all admit it ...</td>\n",
              "      <td>even carat let admit song universal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this song tells that some song s don t need bi...</td>\n",
              "      <td>song tells song need billion views prove legen...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not a fan but i should say that this song is o...</td>\n",
              "      <td>fan say song another level</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4 years have passed and this song is still a l...</td>\n",
              "      <td>years passed song still legend probably legacy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i m not a fan of them but i really like all of...</td>\n",
              "      <td>fan really like songs especially one deserves ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69830</th>\n",
              "      <td>im updated but i want to binge watch more svt ...</td>\n",
              "      <td>updated want binge watch svt videos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69831</th>\n",
              "      <td>anyways im currently binge watching their vliv...</td>\n",
              "      <td>anyways currently binge watching vlives help</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69832</th>\n",
              "      <td>novesuity dino thank you tho ü•∞</td>\n",
              "      <td>novesuity dino thank tho</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69833</th>\n",
              "      <td>lui quinto did you watch seventeen project big...</td>\n",
              "      <td>lui quinto watch seventeen project big debut a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69834</th>\n",
              "      <td>ÎßâÎÇ¥Ïò®ÌÉë seventeen im currently watching those</td>\n",
              "      <td>seventeen currently watching</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69835 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  ... cluster_label\n",
              "0      even if you re not a carat let s all admit it ...  ...             2\n",
              "1      this song tells that some song s don t need bi...  ...             2\n",
              "2      not a fan but i should say that this song is o...  ...             2\n",
              "3      4 years have passed and this song is still a l...  ...             0\n",
              "4      i m not a fan of them but i really like all of...  ...             0\n",
              "...                                                  ...  ...           ...\n",
              "69830  im updated but i want to binge watch more svt ...  ...             0\n",
              "69831  anyways im currently binge watching their vliv...  ...             0\n",
              "69832                     novesuity dino thank you tho ü•∞  ...             1\n",
              "69833  lui quinto did you watch seventeen project big...  ...             0\n",
              "69834         ÎßâÎÇ¥Ïò®ÌÉë seventeen im currently watching those  ...             2\n",
              "\n",
              "[69835 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9nbZ5LiX2RB"
      },
      "source": [
        "# ÌÅ¥Îü¨Ïä§ÌÑ∞Îì§Ïùò ÌïµÏã¨Îã®Ïñ¥ Ï∂îÏ∂ú\n",
        "# https://techblog-history-younghunjo1.tistory.com/114\n",
        "\n",
        "def get_cluster_details(cluster_model, cluster_data, feature_names,\n",
        "                       cluster_num, top_n_features=10):\n",
        "    cluster_details = {}\n",
        "    # Í∞Å ÌÅ¥Îü¨Ïä§ÌÑ∞ Î†àÏù¥Î∏îÎ≥Ñ featureÎì§Ïùò centerÍ∞íÎì§ ÎÇ¥Î¶ºÏ∞®ÏàúÏúºÎ°ú Ï†ïÎ†¨ ÌõÑÏùò Ïù∏Îç±Ïä§Î•º Î∞òÌôò\n",
        "    center_feature_idx = cluster_model.cluster_centers_.argsort()[:,::-1]\n",
        "    \n",
        "    # Í∞úÎ≥Ñ ÌÅ¥Îü¨Ïä§ÌÑ∞ Î†àÏù¥Î∏îÎ≥ÑÎ°ú \n",
        "    for cluster_num in range(cluster_num):\n",
        "        # Í∞úÎ≥Ñ ÌÅ¥Îü¨Ïä§ÌÑ∞Î≥Ñ Ï†ïÎ≥¥Î•º Îã¥ÏùÑ empty dictÌï†Îãπ\n",
        "        cluster_details[cluster_num] = {}\n",
        "        cluster_details[cluster_num]['cluster'] = cluster_num\n",
        "        \n",
        "        # Í∞Å featureÎ≥Ñ centerÍ∞íÎì§ Ï†ïÎ†¨Ìïú Ïù∏Îç±Ïä§ Ï§ë ÏÉÅÏúÑ 10Í∞úÎßå Ï∂îÏ∂ú\n",
        "        top_ftr_idx = center_feature_idx[cluster_num, :top_n_features]\n",
        "        top_ftr = [feature_names[idx] for idx in top_ftr_idx]\n",
        "        # top_ftr_idxÎ•º ÌôúÏö©Ìï¥ÏÑú ÏÉÅÏúÑ 10Í∞ú featureÎì§Ïùò centerÍ∞íÎì§ Î∞òÌôò\n",
        "        # Î∞òÌôòÌïòÍ≤å ÎêòÎ©¥ arrayÏù¥Í∏∞ ÎñÑÎ¨∏Ïóê Î¶¨Ïä§Ìä∏Î°úÎ∞îÍæ∏Í∏∞\n",
        "        top_ftr_val = cluster_model.cluster_centers_[cluster_num, top_ftr_idx].tolist()\n",
        "        \n",
        "        # cluster_details ÎîïÏÖîÎÑàÎ¶¨ÏóêÎã§Í∞Ä Í∞úÎ≥Ñ Íµ∞Ïßë Ï†ïÎ≥¥ ÎÑ£Ïñ¥Ï£ºÍ∏∞\n",
        "        cluster_details[cluster_num]['top_features'] = top_ftr\n",
        "        cluster_details[cluster_num]['top_featrues_value'] = top_ftr_val\n",
        "\n",
        "        # Ìï¥Îãπ cluster_numÏúºÎ°ú Î∂ÑÎ•òÎêú ÌååÏùºÎ™Ö(Î¨∏ÏÑúÎì§) ÎÑ£Ïñ¥Ï£ºÍ∏∞\n",
        "        doc_cl = cluster_data[cluster_data['cluster_label']==cluster_num]['en_sent'] # ÎÅùÏóê en_sent??\n",
        "\n",
        "        # filenamesÍ∞Ä dfÏúºÎ°ú Î∞òÌôòÎêòÍ∏∞ ÎñÑÎ¨∏Ïóê Í∞íÎì§Îßå Ï∂úÎ†•Ìï¥ÏÑú array->listÎ°ú Î≥ÄÌôò\n",
        "        doc_cl = doc_cl.values.tolist()\n",
        "        cluster_details[cluster_num]['en_sent'] = doc_cl\n",
        "    \n",
        "    return cluster_details"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "PEh2vklsX7Bb",
        "outputId": "70a495aa-7c3e-4dd3-9af1-60b6c041355e"
      },
      "source": [
        "def print_cluster_details(cluster_details):\n",
        "    for cluster_num, cluster_detail in cluster_details.items():\n",
        "        print(f\"#####Cluster Num: {cluster_num}\")\n",
        "        print()\n",
        "        print(\"ÏÉÅÏúÑ 10Í∞ú featureÎã®Ïñ¥Îì§:\\n\", cluster_detail['top_features'])\n",
        "        print()\n",
        "        print(f\"Cluster {cluster_num}ÏúºÎ°ú Î∂ÑÎ•òÎêú Î¨∏ÏÑúÎì§:\\n{cluster_detail['comment'][:5]}\")\n",
        "        print('-'*20)\n",
        "\n",
        "feature_names = tfidf.get_feature_names()\n",
        "cluster_details = get_cluster_details(cluster_model=km,\n",
        "                                     cluster_data=docs.comment.values,\n",
        "                                     feature_names=feature_names,\n",
        "                                     cluster_num=4,\n",
        "                                     top_n_features=10)\n",
        "print_cluster_details(cluster_details)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-4241da18dfe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                      \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                      \u001b[0mcluster_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                      top_n_features=10)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint_cluster_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-6f5ad6f6b848>\u001b[0m in \u001b[0;36mget_cluster_details\u001b[0;34m(cluster_model, cluster_data, feature_names, cluster_num, top_n_features)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Ìï¥Îãπ cluster_numÏúºÎ°ú Î∂ÑÎ•òÎêú ÌååÏùºÎ™Ö(Î¨∏ÏÑúÎì§) ÎÑ£Ïñ¥Ï£ºÍ∏∞\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdoc_cl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcluster_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en_sent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# filenamesÍ∞Ä dfÏúºÎ°ú Î∞òÌôòÎêòÍ∏∞ ÎñÑÎ¨∏Ïóê Í∞íÎì§Îßå Ï∂úÎ†•Ìï¥ÏÑú array->listÎ°ú Î≥ÄÌôò\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9tp_D_lXyJf"
      },
      "source": [
        " # ÎπàÎèÑÎ∂ÑÏÑù"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11SB0FCMQQxb"
      },
      "source": [
        "# from collections import Counter \n",
        "\n",
        "# def scan_vocabulary(sents, tokenize, min_conunt=2): \n",
        "\n",
        "#   counter = Counter(w for sent in sents for w in tokenize(sent)) \n",
        "#   counter = {w: c for w, c in counter.items() if c >= min_count} \n",
        "#   idx_to_vocab = [w for w, _ in sorted(counter.items(), key:lambda x:-x[1])] \n",
        "#   vocab_to_idx = {vocab:idx for idx, vocab in enumerate(idx_to_vocab)} \n",
        "\n",
        "# return idx_to_vocab, vocab_to_idx\n",
        "\n",
        "# Ï∂úÏ≤ò: https://ebbnflow.tistory.com/292 [Dev Log : ÏÇ∂ÏùÄ ÌôïÎ•†Ïùò Íµ¨Î¶Ñ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biy8kA1dCAVR"
      },
      "source": [
        "# km = KMeans(n_clusters=3)\n",
        "# # inertia_arr = np.array(y).reshape(-1,1)\n",
        "\n",
        "# km.fit(x,y)\n",
        "\n",
        "# check how many unique labels do you have\n",
        "# np.unique(km.labels_)\n",
        "# #array([0, 1, 2], dtype=int32)\n",
        "\n",
        "# km.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FznpHmrfPuzP"
      },
      "source": [
        "# ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅÎêú Î¨∏ÏÑúÎì§ Ï§ëÏóêÏÑú ÌäπÏ†ï Î¨∏ÏÑúÎ•º ÌïòÎÇò ÏÑ†ÌÉùÌïú ÌõÑ ÎπÑÏä∑Ìïú Î¨∏ÏÑú Ï∂îÏ∂ú\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "hotel_idx = document_df[document_df['cluster_label']==1].index\n",
        "print(\"Ìò∏ÌÖî Ïπ¥ÌÖåÍ≥†Î¶¨Î°ú ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅÎêú Î¨∏ÏÑúÎì§Ïùò Ïù∏Îç±Ïä§:\\n\",hotel_idx)\n",
        "print()\n",
        "# Ìò∏ÌÖî Ïπ¥ÌÖåÍ≥†Î¶¨Î°ú ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅ Îêú Î¨∏ÏÑúÎì§Ïùò Ïù∏Îç±Ïä§ Ï§ë ÌïòÎÇò ÏÑ†ÌÉùÌï¥ ÎπÑÍµê Í∏∞Ï§ÄÏúºÎ°ú ÏÇºÏùÑ Î¨∏ÏÑú ÏÑ†Ï†ï\n",
        "comparison_doc = document_df.iloc[hotel_idx[0]]['filename']\n",
        "print(\"##Ïú†ÏÇ¨ÎèÑ ÎπÑÍµê Í∏∞Ï§Ä Î¨∏ÏÑú Ïù¥Î¶Ñ:\",comparison_doc,'##')\n",
        "print()\n",
        "\n",
        "# ÏúÑÏóêÏÑú Ï∂îÏ∂úÌïú Ìò∏ÌÖî Ïπ¥ÌÖåÍ≥†Î¶¨Î°ú ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅÎêú Î¨∏ÏÑúÎì§Ïùò Ïù∏Îç±Ïä§ Ï§ë 0Î≤àÏù∏Îç±Ïä§(ÎπÑÍµêÍ∏∞Ï§ÄÎ¨∏ÏÑú)Ï†úÏô∏Ìïú\n",
        "# Îã§Î•∏ Î¨∏ÏÑúÎì§Í≥ºÏùò Ïú†ÏÇ¨ÎèÑ Ï∏°Ï†ï\n",
        "similarity = cosine_similarity(ftr_vect[hotel_idx[0]], ftr_vect[hotel_idx])\n",
        "print(similarity)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOxqJbsKP3N8"
      },
      "source": [
        "# ÎπÑÍµêÍ∏∞Ï§Ä Î¨∏ÏÑúÏôÄ Îã§Î•∏ Î¨∏ÏÑúÎì§Í∞ÑÏùò Ïú†ÏÇ¨ÎèÑ ÏÇ¥Ìé¥Î≥¥Í∏∞\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# array ÎÇ¥Î¶ºÏ∞®ÏàúÏúºÎ°ú Ï†ïÎ†¨Ìïú ÌõÑ Ïù∏Îç±Ïä§ Î∞òÌôò [:,::-1] Î™®Îì†ÌñâÏóê ÎåÄÌï¥ÏÑú Ïó¥ÏùÑ ÎÇ¥Î¶ºÏ∞®ÏàúÏúºÎ°ú!\n",
        "sorted_idx = similarity.argsort()[:,::-1]\n",
        "# ÎπÑÍµêÎ¨∏ÏÑú ÎãπÏÇ¨ÏûêÎäî Ï†úÏô∏Ìïú Ïù∏Îç±Ïä§ Ï∂îÏ∂ú\n",
        "sorted_idx = sorted_idx[:, 1:]\n",
        "\n",
        "# Ïú†ÏÇ¨ÎèÑÍ∞Ä ÌÅ∞ ÏàúÏúºÎ°ú hotel_idx(label=1Ïù∏ Ï¶â, Ìò∏ÌÖîÍ≥ºÍ¥ÄÎ†®Îêú ÎÇ¥Ïö©Ïùò Î¨∏ÏÑúÏù¥Î¶ÑÎì§Ïùò indexÎì§)ÏóêÏÑú Ïû¨ Ï†ïÎ†¨ \n",
        "# indexÎ°ú ÎÑ£ÏúºÎ†§Î©¥ 1Ï∞®ÏõêÏúºÎ°ú reshapeÌï¥Ï£ºÍ∏∞!\n",
        "hotel_sorted_idx = hotel_idx[sorted_idx.reshape(-1,)]\n",
        "# Ïú†ÏÇ¨ÎèÑ ÌñâÎ†¨Í∞íÎì§ÏùÑ Ïú†ÏÇ¨ÎèÑÍ∞Ä ÌÅ∞ ÏàúÏúºÎ°ú Ïû¨Ï†ïÎ†¨(ÎπÑÍµê Î¨∏ÏÑú ÎãπÏÇ¨ÏûêÎäî Ï†úÏô∏)\n",
        "hotel_sim_values = np.sort(similarity.reshape(-1,))[::-1]\n",
        "hotel_sim_values = hotel_sim_values[1:]\n",
        "# Ïù¥Î†áÍ≤å ÎêòÎ©¥ ÎπÑÍµêÎ¨∏ÏÑúÏôÄ Í∞ÄÏû• Ïú†ÏÇ¨Ìïú ÏàúÏúºÎ°ú 'Ìï¥ÎãπÎ¨∏ÏÑúÏùòindex-Ïú†ÏÇ¨ÎèÑÍ∞í' ÏúºÎ°ú ÎèôÏùºÌïú ÏúÑÏπòÍ∞Ä Îß§ÌïëÎêú Îëê Í∞úÏùò array!\n",
        "# Í∑∏ÎûòÏÑú Í∑∏ÎåÄÎ°ú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùò Í∞Å ÏπºÎüºÏúºÎ°ú ÎÑ£Ïñ¥Ï£ºÍ∏∞\n",
        "print(hotel_sorted_idx)\n",
        "print(hotel_sim_values)\n",
        "print()\n",
        "print(\"Í∏∏Ïù¥ ÎπÑÍµê\", len(hotel_sorted_idx), len(hotel_sim_values))\n",
        "print()\n",
        "# Îπà Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ±\n",
        "hotel_sim_df = pd.DataFrame()\n",
        "# hotel_sorted_idx ÏôÄ hotel_sim_values Îß§ÌïëÏãúÌÇ® arrayÏûÑ\n",
        "hotel_sim_df['filename'] = document_df.iloc[hotel_sorted_idx]['filename']\n",
        "hotel_sim_df['similarity'] = hotel_sim_values\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.barplot(data=hotel_sim_df, x='similarity', y='filename')\n",
        "plt.title(comparison_doc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}